{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_mixed wav (17280, 22239)\n",
      "0_mixed wav (16640, 22879)\n",
      "1_mixed wav (17440, 22239)\n",
      "1_mixed wav (16800, 22879)\n",
      "2_mixed wav (17920, 21919)\n",
      "2_mixed wav (17280, 22559)\n",
      "3_mixed wav (18080, 21599)\n",
      "3_mixed wav (17440, 22239)\n",
      "4_mixed wav (17280, 22239)\n",
      "4_mixed wav (16640, 22879)\n",
      "5_mixed wav (17440, 22239)\n",
      "5_mixed wav (16800, 22879)\n",
      "6_mixed wav (17920, 21919)\n",
      "6_mixed wav (17280, 22559)\n",
      "7_mixed wav (18080, 21599)\n",
      "7_mixed wav (17440, 22239)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "import librosa\n",
    "import os\n",
    "import soundfile\n",
    "\n",
    "cmap_plot = plt.cm.bone_r\n",
    "minpercentile=80\n",
    "FIG_SIZE = (14,10)\n",
    "\n",
    "####################\n",
    "# 주파수 그림 및 FIR filter 적용\n",
    "####################\n",
    "def decibel_sq_safe(x, epsilon=1e-10):\n",
    "    return 10*np.log10(np.maximum(np.real(x*np.conj(x)),epsilon))\n",
    "\n",
    "def getFIRFFT(H, order, winname=None) :\n",
    "    NFFT = (len(H)-1)*2\n",
    "    # Mirror Image of 'Real Value' & Initialize the imaginary value to 0\n",
    "    H = np.concatenate((H, H[-2:0:-1])) + np.zeros(NFFT)*(1j)\n",
    "    \n",
    "    h = np.fft.ifft(H, NFFT)\n",
    "    \n",
    "    order = min(NFFT-1, order)\n",
    "    h = np.concatenate((h[(len(h)-order//2):], h[0:order//2+1]))\n",
    "    if winname != None:\n",
    "        win = librosa.filters.get_window(winname, order+1, fftbins=False)\n",
    "        h = h*win\n",
    "    return h.real\n",
    "\n",
    "def drawspectrogram2(x, Nf, Fs, Ns=None, winname='hamming', minpercentile=80, isdbscale=True, isdraw=True):\n",
    "    # Short-time Fourier transform with half-overlap \n",
    "    # Nf: analysis size\n",
    "    # Ns: shift size \n",
    "    # NFFT: FFT size, power of 2\n",
    "    if Ns==None: Ns=Nf//2\n",
    "    num_frames = (len(x)-Nf)//Ns+1  # 마지막 채워지지 않은 프레임은 버린다. 구현에 따라 zero-padding해서 사용 가능\n",
    "    NFFT = int(2**(np.ceil(np.log2(Nf))))   # Nf보다 크거나 같은 2의 거듭제곱을 NFFT 로 정의\n",
    "    hNo = NFFT//2+1\n",
    "    X = np.zeros((hNo,num_frames))\n",
    "    \n",
    "    # generate window\n",
    "    if winname=='rect' or winname=='rectangular':\n",
    "        win = np.ones(Nf)\n",
    "    else:   # hamming, hann, etc.\n",
    "        win = librosa.filters.get_window(winname, Nf, fftbins=True)\n",
    "        \n",
    "    # STFT\n",
    "    for i in range(num_frames):\n",
    "        y = np.fft.fft(win*x[(i*Ns):(i*Ns+Nf)], n=NFFT)\n",
    "        y = y[:hNo]\n",
    "        if isdbscale: y = decibel_sq_safe(y)\n",
    "        else: y = np.abs(y)\n",
    "        X[:,i] = y\n",
    "\n",
    "    if isdraw:\n",
    "        # 상위 80% 정도만 scale 한다. imshow의 vmin vmax 이용 \n",
    "        vmax = np.max(X[:])\n",
    "        vmin = np.percentile(X[:], minpercentile)\n",
    "        specgram_axis = [0,float(len(x))/float(Fs),0,float(Fs)/2]\n",
    "        plt.imshow(X, cmap=cmap_plot, aspect='auto', origin='lower', extent=specgram_axis, vmax=vmax, vmin=vmin)\n",
    "        plt.xlabel('time (seconds)')\n",
    "        plt.ylabel('frequency (Hz)')\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def midian_filter(x, len_filter=5) :\n",
    "    wav = np.zeros(len(x))\n",
    "    bi_len_filter = 0\n",
    "    if len_filter%2 == 1:\n",
    "        bi_len_filter = 1\n",
    "    for i in range(len(x)) :\n",
    "        wav[i] = np.median(np.concatenate([x[i-(len_filter//2):i], x[i:i+(len_filter//2)+bi_len_filter]]))\n",
    "        \n",
    "    return wav\n",
    "\n",
    "\n",
    "###########################################\n",
    "# noise 구간 에너지 구하기\n",
    "###########################################\n",
    "def Energy_Noise(x, Tf, Tn, Ts, fs) :\n",
    "    #Ns : shift samples, Nf : process samples, Nn : Noise samples\n",
    "    Ns = int(Ts*fs)\n",
    "    Nf = int(Tf*fs)\n",
    "    Nn = int(Tn*fs)\n",
    "    NFFT = int(2**(np.ceil(np.log2(Nf))))\n",
    "    hNo = NFFT//2+1\n",
    "    Pnn = np.zeros(hNo) \n",
    "    nframes = int((Nn-Nf)//Ns+1)\n",
    "    for n in range(nframes):\n",
    "        y = x[(n*Ns):(n*Ns)+Nf]\n",
    "        Y = np.fft.fft(y, NFFT)\n",
    "        aX2 = (Y*np.conj(Y))\n",
    "        Pnn += aX2[:hNo].real\n",
    "    Pnn = Pnn/nframes\n",
    "    return Pnn\n",
    "\n",
    "############################################\n",
    "# fir filter 적용\n",
    "############################################\n",
    "def FIR_process(x, Tf, Ts, fs, Pnn, order) :\n",
    "    Ns = int(Ts*fs)\n",
    "    Nf = int(Tf*fs)\n",
    "    NFFT = int(2**(np.ceil(np.log2(Nf))))\n",
    "    hNo = NFFT//2+1\n",
    "    nframes = int((len(x)-Nf)//Ns+1)\n",
    "    pre_x = np.zeros(Ns)\n",
    "    \n",
    "    win = librosa.filters.get_window('hamming', Nf, fftbins=True)\n",
    "    x_hat = np.zeros(Ns*nframes)\n",
    "    for n in range(nframes):\n",
    "        y = x[(n*Ns):(n*Ns)+Nf]\n",
    "        Y = np.fft.fft(y, NFFT)\n",
    "        aX2 = (Y*np.conj(Y))\n",
    "        \n",
    "        # |X(w)|^2 / |X(w)+ N(x)|^2\n",
    "        H_w = (aX2[:hNo].real - Pnn)/aX2[:hNo].real\n",
    "        # set bound(-3db)\n",
    "        H_w = np.maximum(H_w,0.224)\n",
    "        \n",
    "        h = getFIRFFT(np.array(H_w), order, winname='hamming')\n",
    "        x2 = signal.lfilter(h, [1], x[(n*Ns):(n*Ns)+Nf])\n",
    "        \n",
    "        x2 = x2*win\n",
    "        x_hat[n*Ns:(n+1)*Ns] = x2[:Ns]+pre_x\n",
    "        pre_x = x2[-Ns:]\n",
    "        \n",
    "    return x_hat\n",
    "\n",
    "###################################\n",
    "# voice, unvoice 판단\n",
    "###################################\n",
    "def V_UV(x, Tf, Ts, fs, Pnn, rate=1.0) :\n",
    "    Ns = int(Ts*fs)\n",
    "    Nf = int(Tf*fs)\n",
    "    NFFT = int(2**(np.ceil(np.log2(Nf))))\n",
    "    hNo = NFFT//2+1\n",
    "    nframes = int((len(x)-Nf)//Ns+1)\n",
    "    VUV = np.zeros(nframes, dtype = float)\n",
    "\n",
    "    threshold_noise = np.sqrt(np.average(Pnn)) * rate\n",
    "    for n in range(nframes):\n",
    "        y = x[(n*Ns):(n*Ns)+Nf]\n",
    "        Y = np.fft.fft(y, NFFT)\n",
    "        aX2 = (Y*np.conj(Y))\n",
    "        if np.sqrt(np.average(aX2[:hNo].real)) > threshold_noise :\n",
    "            VUV[n] = 1.0\n",
    "    \n",
    "    return VUV\n",
    "\n",
    "\n",
    "###################################\n",
    "# EPD(end point detection)\n",
    "###################################\n",
    "def EPD(x, Tf, Ts, Fs, E_N, VUV) :\n",
    "    Ns = int(Fs*Ts)\n",
    "    # threshold는 noise 평균의 1.2 (1.3~1.5까지 유사)\n",
    "    VUV = V_UV(x, Tf, Ts, Fs, E_N, 1.2)\n",
    "    # middian filter (앞뒤 2frame 하여 총 5frame)\n",
    "    VUV_mid = midian_filter(VUV)\n",
    "\n",
    "    # 음성구간을 찾기 위해 가장 긴 구간 찾기\n",
    "    max_len = 0\n",
    "    checking = False\n",
    "    for i in range(len(VUV_mid)) :\n",
    "        if VUV_mid[i] == 1.0 and not checking :\n",
    "            checking = True\n",
    "            temp_len = Ns\n",
    "            temp_start = i*Ns\n",
    "        elif VUV_mid[i] == 1.0 and checking :\n",
    "            temp_len = temp_len + Ns\n",
    "        elif (VUV_mid[i] == 0.0 or i == len(VUV_mid)-1)and checking :\n",
    "            checking = False\n",
    "            if temp_len > max_len :\n",
    "                max_len = temp_len\n",
    "                start_point = temp_start\n",
    "                end_point = (i*Ns) -1\n",
    "                if i == len(VUV_mid)-1 :\n",
    "                    end_point = ((i+1)*Ns) -1\n",
    "    \n",
    "    return VUV, VUV_mid, start_point, end_point\n",
    "\n",
    "\n",
    "def All_Noise_Avg(x, Tf, Ts, fs, start, end) :\n",
    "    #Ns : shift samples, Nf : process samples, Nn : Noise samples\n",
    "    Ns = int(Ts*fs)\n",
    "    Nf = int(Tf*fs)\n",
    "    NFFT = int(2**(np.ceil(np.log2(Nf))))\n",
    "    hNo = NFFT//2+1\n",
    "    Pnn = np.zeros(hNo) \n",
    "    nframes = int((len(x)-Nf)//Ns+1)\n",
    "\n",
    "    num_noise = 0\n",
    "    for n in range(nframes):\n",
    "        if n*Ns >= start and n*Ns <= end:\n",
    "            continue\n",
    "        y = x[(n*Ns):(n*Ns)+Nf]\n",
    "        Y = np.fft.fft(y, NFFT)\n",
    "        aX2 = (Y*np.conj(Y))\n",
    "        Pnn += aX2[:hNo].real\n",
    "        num_noise = num_noise+1\n",
    "    Pnn = Pnn/num_noise\n",
    "    return Pnn\n",
    "\n",
    "def main() :\n",
    "    speechfile = \"gjang-kdigits0-3\"\n",
    "    noisefiles = ['car', 'car2']\n",
    "    path_save = 'result_jwJang'\n",
    "    order = 62\n",
    "    sr = 16000\n",
    "    Ts = 0.01\n",
    "    Tf = 0.02\n",
    "\n",
    "    # (speech and noise) load\n",
    "    speech, Fs = librosa.load(f'{speechfile}.wav', sr = sr)\n",
    "    noises = []\n",
    "    for noisefile in noisefiles :\n",
    "        noise, Fs = librosa.load(f'{noisefile}.wav', sr = sr)\n",
    "        noises.append(noise)\n",
    "\n",
    "    # make mixed wav\n",
    "    std_s = np.sqrt(np.mean(speech**2))\n",
    "    mixsnrs = np.array([20, 10, 0, -10])\n",
    "    std_n = []\n",
    "    for i in range(len(noises)) :\n",
    "        std_n.append(np.std(noises[i]))\n",
    "    std_n = np.array(std_n)\n",
    "    mixedSigs = []\n",
    "\n",
    "    for n in range(len(noises)) :\n",
    "        for snr in mixsnrs:\n",
    "            gain = np.power(10, -snr/20)\n",
    "            m = speech + noises[i][:len(speech)]/std_n[i]*std_s*gain\n",
    "            mixedSigs.append(m)\n",
    "    \n",
    "    for num in range(len(mixedSigs)) :\n",
    "        os.system('mkdir -p %s'%os.path.join(path_save, f'{num}_mixed_file'))\n",
    "        plt.figure(figsize=FIG_SIZE)\n",
    "        plt.subplot(5,2,1)\n",
    "        X=drawspectrogram2(speech, int(Tf*Fs), Fs)\n",
    "        plt.subplot(5,2,2)\n",
    "        plt.plot(speech)\n",
    "        soundfile.write(os.path.join(path_save, f'{num}_mixed_file', '0_speech.wav'), speech, Fs)\n",
    "        \n",
    "        plt.subplot(5,2,3)\n",
    "        X=drawspectrogram2(mixedSigs[num], int(Tf*Fs), Fs)\n",
    "        plt.subplot(5,2,4)\n",
    "        plt.plot(mixedSigs[num])\n",
    "        soundfile.write(os.path.join(path_save, f'{num}_mixed_file', '1_mix.wav'), mixedSigs[num], Fs)\n",
    "\n",
    "        #0.5s에 대한 noise 계산\n",
    "        Tn = 0.5\n",
    "        E_N = Energy_Noise(mixedSigs[num], Tf, Tn, Ts, Fs)\n",
    "        \n",
    "        #1.0.5ms에 대한 noise를 이용하여 이를 차감하는 FIR filter 구현\n",
    "        x_hat = FIR_process(mixedSigs[num], Tf, Ts, Fs, E_N, order)\n",
    "        plt.subplot(5,2,5)\n",
    "        X2 =drawspectrogram2(x_hat, int(Tf*Fs), Fs)\n",
    "        plt.subplot(5,2,6)\n",
    "        plt.plot(x_hat)\n",
    "        soundfile.write(os.path.join(path_save, f'{num}_mixed_file', '2_FIR_500ms.wav'), x_hat, Fs)\n",
    "\n",
    "        # 2. energy 기반 EPD(end point dectection) 구현\n",
    "        (VUV, VUV_mid, start_point, end_point) = EPD(mixedSigs[num], Tf, Ts, Fs, E_N, 1.2)\n",
    "\n",
    "        # middian filter 적용한 그림.\n",
    "        vuv_mid = np.zeros(len(mixedSigs[num]), dtype=float)\n",
    "        for i in range(len(VUV_mid)) :\n",
    "            vuv_mid[i*int(Ts*Fs):(i+1)*int(Ts*Fs)] = VUV_mid[i]\n",
    "        plt.subplot(5,2,7)\n",
    "        plt.plot(mixedSigs[num])\n",
    "        plt.plot(vuv_mid)\n",
    "\n",
    "        # middian filter 적용하지 않은 그림.\n",
    "        vuv = np.zeros(len(mixedSigs[num]), dtype=float)\n",
    "        for i in range(len(VUV_mid)) :\n",
    "            vuv[i*int(Ts*Fs):(i+1)*int(Ts*Fs)] = VUV[i]\n",
    "        plt.subplot(5,2,8)\n",
    "        plt.plot(vuv)\n",
    "\n",
    "        print(f'{num}_mixed wav ({start_point}, {end_point})')\n",
    "        # 무성자음 및 fading-out 포함(40ms)\n",
    "        padding = 0.04\n",
    "        # reference : 후행하는 유,무성자음에 의한 모음의 지속시간 고찰\n",
    "        start_point = np.maximum(start_point - int(padding*Fs), 0)\n",
    "        end_point = np.minimum(end_point + int(padding*Fs), len(mixedSigs[num])-1)\n",
    "        print(f'{num}_mixed wav ({start_point}, {end_point})')\n",
    "\n",
    "        # 모든 Noise 구간에 대하여 |N(w)|^2 계산\n",
    "        N_all = All_Noise_Avg(mixedSigs[num], Tf, Ts, Fs, start_point, end_point)\n",
    "        # 모든 Noise 구간에 대한 |N(w)|^2 으로 FIR filter 적용\n",
    "        x_hat_2 = FIR_process(mixedSigs[num], Tf, Ts, Fs, N_all, order)\n",
    "        plt.subplot(5,2,9)\n",
    "        X2 =drawspectrogram2(x_hat_2, int(Tf*Fs), Fs)\n",
    "        plt.subplot(5,2,10)\n",
    "        plt.plot(x_hat_2)\n",
    "        soundfile.write(os.path.join(path_save, f'{num}_mixed_file', '3_FIR_all_noise.wav'), x_hat_2, Fs)\n",
    "        plt.savefig(os.path.join(path_save, f'{num}_mixed_file', 'fig.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__' :\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
